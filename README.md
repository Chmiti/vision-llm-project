# ğŸ§  Vision-Language Intelligent QA System

Un projet de gÃ©nÃ©ration de lÃ©gendes d'images, question-rÃ©ponse visuelle et raisonnement assistÃ© par LLM, combinant les modÃ¨les BLIP, CLIP, FAISS et une interface Gradio.

---

## ğŸ“¸ FonctionnalitÃ©s principales

- ğŸ” GÃ©nÃ©ration de lÃ©gendes Ã  partir dâ€™images (BLIP)
- â“ Question-RÃ©ponse visuelle avec prompt engineering
- ğŸ§  Raisonnement intelligent Ã  lâ€™aide dâ€™un LLM (OpenAI GPT)
- ğŸ“š SystÃ¨me RAG : Recherche augmentÃ©e via CLIP + FAISS
- ğŸ–¥ï¸ Interface interactive via Gradio

---

## ğŸ› ï¸ Stack technique

| Composant        | RÃ´le                                          |
|------------------|-----------------------------------------------|
| `BLIP`           | GÃ©nÃ©ration automatique de lÃ©gendes dâ€™images   |
| `CLIP`           | Encodage visuel et recherche dâ€™images similaires |
| `FAISS`          | Indexation rapide pour recherche de similaritÃ© |
| `OpenAI GPT`     | Raisonnement et gÃ©nÃ©ration de rÃ©ponses         |
| `Gradio`         | Interface web simple et rapide                 |
| `Python`         | Langage principal (avec PyTorch, Transformers) |

---

## ğŸ§ª DÃ©mo rapide

1. ğŸ“¤ Upload une image
2. âœï¸ Pose une question (ex: *Quel est ce panneau ?*)
3. ğŸ¤– Le systÃ¨me :
   - GÃ©nÃ¨re une lÃ©gende avec BLIP
   - Cherche des images similaires avec CLIP + FAISS
   - Envoie le tout Ã  GPT pour obtenir une rÃ©ponse contextualisÃ©e
4. ğŸ’¬ RÃ©ponse affichÃ©e via Gradio

---

## ğŸ”§ Lancer le projet

```bash
# CrÃ©e ton environnement
python -m venv venv
source venv/bin/activate  # ou venv\Scripts\activate sous Windows

# Installe les dÃ©pendances
pip install -r requirements.txt

# Lance l'app Gradio
python app.py
ğŸ“ Organisation du projet
bash
Copy
Edit
VISION-LLM-PROJECT/
â”‚
â”œâ”€â”€ app/                  # Fichiers principaux dâ€™infÃ©rence
â”œâ”€â”€ models/               # Scripts pour BLIP, CLIP, FAISS
â”œâ”€â”€ pipeline/             # Ã‰tapes de pipeline
â”œâ”€â”€ data/                 # Images, index FAISS, mÃ©tadonnÃ©es
â”œâ”€â”€ .gradio/ .env .gitignore requirements.txt README.md
```
âš ï¸ Limitations actuelles et ouverture:

ğŸ¯ PrÃ©cision variable des captions gÃ©nÃ©rÃ©es (manque dâ€™adaptation au domaine)

ğŸ“‰ QualitÃ© des rÃ©ponses dÃ©pend fortement de la base CLIP + FAISS

ğŸ§Š Temps de rÃ©ponse Ã©levÃ© sans optimisation hardware (GPU)

ğŸ§  LLM non fine-tunÃ© sur les requÃªtes spÃ©cifiques du domaine

ğŸ”œ Ces limites mâ€™ont inspirÃ© un projet plus ambitieux, oÃ¹ je vais :

Fine-tuner BLIP et CLIP sur un dataset spÃ©cialisÃ© (ex. panneaux de signalisation, objets mÃ©dicauxâ€¦)

CrÃ©er une base multimodale enrichie (image + texte + tags)

IntÃ©grer un LLM open-source finement ajustÃ© pour du Q&A intelligent

Optimiser le systÃ¨me avec quantization / onnx / GPU / Docker

ğŸ’¡ Ce projet servira donc de fondation pour une version plus robuste, plus rapide et plus prÃ©cise dâ€™un systÃ¨me de question-rÃ©ponse visuelle intelligent.

ğŸ‘¤ Auteur
Taha Chmiti
Ã‰lÃ¨ve-ingÃ©nieur Ã  lâ€™ENSEIRB-Matmeca
SpÃ©cialisÃ© en Traitement dâ€™image et Intelligence Artificielle
ğŸ“« taha.chmiti@enseirb-matmeca.fr

â­ Pourquoi ce projet ?
Ce projet montre ma capacitÃ© Ã  :

IntÃ©grer plusieurs modÃ¨les IA dans un pipeline cohÃ©rent

Concevoir un systÃ¨me multi-modÃ¨le basÃ© sur l'image et le langage

Construire une interface interactive et exploitable en local

Prendre du recul sur les limites et identifier des perspectives concrÃ¨tes